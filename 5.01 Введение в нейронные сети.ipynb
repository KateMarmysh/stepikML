{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Шаг № 1 блока «5.1 Введение в нейронные сети»\n",
    "Обучите нейронную сеть на датасете mnist. Добейтесь точности предсказания выше 97.5% на валидационном датасете\n",
    "\n",
    "(10 баллов)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Flatten"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Загрузим данные из датасета mnist"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Определим размерность выборок"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "y_train shape: (60000,)\n",
      "x_test shape: (10000, 28, 28)\n",
      "y_test shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('x_train shape:', x_train.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "\n",
    "# выводим размерность (формат матрицы) ..., где первый элемент кортежа - количество строк, а второй - количество столбцов"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Произведем предобработку тренировочных и тестовых данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 28, 28, 1))  # Входные изображения в наборе данных MNIST представлены в виде массивов из 28х28 пикселей. Этот код преобразует каждый массив в трехмерный массив размера 28х28х1 для работы в нейронной сети. Поскольку мы имеем чёрно-белое изображение (1-ый канал), то мы добавляем 1 в конце.\n",
    "\n",
    "x_train = x_train / 255.  # Нормализуем значения пикселей изображения в диапазоне от 0 до 1.\n",
    "\n",
    "y_train = to_categorical(y_train)  #В нейронной сети используется one-hot encoding для меток классов. Это означает, что каждая метка класса будет представлена в виде вектора, длиной равной количеству классов, где все значения равны 0 за исключением одного, который равен 1.\n",
    "\n",
    "x_test = x_test.reshape((10000, 28, 28, 1))\n",
    "x_test = x_test / 255.\n",
    "y_test = to_categorical(y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Создадим модель нейронной сети при помощи библиотеки Keras с несколькими слоями.\n",
    "\n",
    "Первый слой этой модели - Conv2D - это сверточный слой, который выполняет операцию свертки на изображении. Он используется для извлечения признаков из изображения. Conv2D принимает несколько аргументов:\n",
    "\n",
    "- Количество фильтров (32). Каждый фильтр извлекает различные признаки из изображения.\n",
    "- Размер ядра (3, 3). Ядро - это матрица, которая \"скользит\" по изображению и применяет операцию свертки. Размер ядра определяет, какие признаки будут извлечены из изображения.\n",
    "- Функция активации (relu). Функции активации используются для добавления нелинейности в модель. Rectified Linear Unit (ReLU) - это одна из наиболее популярных функций активации, которая широко используется в сверточных нейронных сетях.\n",
    "\n",
    "Второй слой - MaxPooling2D - выполняет операцию объединения (pooling) на признаках, извлеченных из изображения. Он используется для уменьшения размерности признаков, ускорения вычислений и предотвращения переобучения. MaxPooling2D принимает аргумент pool_size, который определяет размер объединяемой области.\n",
    "\n",
    "Третий слой - Flatten - преобразует выходные данные, полученные из предыдущего слоя, в плоский массив. Эта операция не извлекает признаки, а просто преобразует матрицу в вектор\n",
    "\n",
    "Четвертый слой является полносвязным (dense) с 10 выходами и активационной функцией softmax.\n",
    "Softmax - это функция активации, которая часто используется в выходном слое нейросетей для многоклассовой классификации. Функция принимает вектор значений и вычисляет вероятности принадлежности каждого значения к одному из классов. Применение функции softmax преобразует вектор выхода последнего слоя нейросети в вектор вероятностей для каждого класса.\n",
    "\n",
    "В итоге получается 4 слоя:\n",
    "\n",
    "1. Сверточный слой (Convolutional Layer)\n",
    "2. Слой подвыборки (Max Pooling Layer)\n",
    "3. Слой выравнивания (Flatten Layer)\n",
    "4. Полносвязный слой (Dense Layer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Создание модели\n",
    "model = Sequential()\n",
    "\n",
    "# Первый слой (добавляется сверточный слой с 32 фильтрами размера 3x3 и активационной функцией ReLU)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# Второй слой (слой подвыборки (pooling) с размером окна 2x2)\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Третий слой (слой выравнивания (flatten), который преобразует выходные данные предыдущего слоя в одномерный массив)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Четвертый слой (полносвязный слой (dense) со 10 выходами и активационной функцией softmax)\n",
    "model.add(Dense(10, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Компиляция и обучение созданной модели нейронной сети:\n",
    "Компилируем созданную модель, используя оптимизатор 'adam', функцию потерь 'categorical_crossentropy' (потери в многоклассовой классификации), и метрику 'accuracy' (точность классификации).\n",
    "Затем обучим на наборе данных обучения `x_train` и `y_train` в течение 5 эпох (одна эпоха - один проход через все данные), с размером пакета (`batch_size`) 32. Используем параметр `validation_data` для передачи в функцию тестового набора данных. Это позволит оценить производительность модели в процессе обучения на отдельном наборе данных, который не участвует в процессе обучения."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.2230 - accuracy: 0.9373 - val_loss: 0.1003 - val_accuracy: 0.9718\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 16s 8ms/step - loss: 0.0854 - accuracy: 0.9752 - val_loss: 0.0742 - val_accuracy: 0.9760\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0645 - accuracy: 0.9812 - val_loss: 0.0642 - val_accuracy: 0.9789\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0537 - accuracy: 0.9835 - val_loss: 0.0537 - val_accuracy: 0.9825\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0455 - accuracy: 0.9864 - val_loss: 0.0535 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x139303ee3b0>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=32, validation_data=(x_test, y_test))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оценка производительности модели на тестовых данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 729/1875 [==========>...................] - ETA: 13s - loss: 0.0783 - accuracy: 0.9783"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9831\n",
      "Test loss: 5.4%\n",
      "Test accuracy: 98.3%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f'Test loss: {round((test_loss* 100), 1)}%\\nTest accuracy: {round((test_acc * 100), 1)}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
